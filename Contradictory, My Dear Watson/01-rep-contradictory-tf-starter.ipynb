{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Contradictory, My Dear Watson\n\nCan machines determine the relationships between sentences?\n\nGiven two sentences, there are three ways they could be related:\n* one could entail the other\n* one could contradict the other\n* they could be unrelated","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom transformers import BertTokenizer, TFBertModel\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-21T20:50:47.284770Z","iopub.execute_input":"2024-09-21T20:50:47.285093Z","iopub.status.idle":"2024-09-21T20:51:28.790858Z","shell.execute_reply.started":"2024-09-21T20:50:47.285063Z","shell.execute_reply":"2024-09-21T20:51:28.789845Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nWARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1726951878.662891      13 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD0921 20:51:18.671331815      13 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD0921 20:51:18.671348099      13 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD0921 20:51:18.671351792      13 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD0921 20:51:18.671354683      13 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD0921 20:51:18.671357480      13 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD0921 20:51:18.671360222      13 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD0921 20:51:18.671362897      13 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD0921 20:51:18.671365488      13 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD0921 20:51:18.671368062      13 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD0921 20:51:18.671370734      13 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD0921 20:51:18.671374529      13 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD0921 20:51:18.671378863      13 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD0921 20:51:18.671381466      13 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD0921 20:51:18.671384000      13 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD0921 20:51:18.671386532      13 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD0921 20:51:18.671389072      13 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD0921 20:51:18.671391769      13 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD0921 20:51:18.671394607      13 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD0921 20:51:18.671397450      13 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD0921 20:51:18.671400294      13 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD0921 20:51:18.671403240      13 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD0921 20:51:18.671405919      13 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD0921 20:51:18.671408586      13 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD0921 20:51:18.671411180      13 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD0921 20:51:18.671413631      13 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD0921 20:51:18.671416101      13 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD0921 20:51:18.671418686      13 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD0921 20:51:18.671421232      13 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD0921 20:51:18.671423891      13 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD0921 20:51:18.671427326      13 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD0921 20:51:18.671430212      13 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD0921 20:51:18.671433049      13 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD0921 20:51:18.671435940      13 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD0921 20:51:18.671438541      13 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD0921 20:51:18.671441084      13 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD0921 20:51:18.671443623      13 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD0921 20:51:18.671446104      13 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD0921 20:51:18.671448598      13 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD0921 20:51:18.671451188      13 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD0921 20:51:18.671453734      13 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD0921 20:51:18.671456220      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD0921 20:51:18.671458704      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD0921 20:51:18.671461249      13 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD0921 20:51:18.671463836      13 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD0921 20:51:18.671466393      13 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI0921 20:51:18.671681149      13 ev_epoll1_linux.cc:123]               grpc epoll fd: 60\nD0921 20:51:18.671693752      13 ev_posix.cc:113]                      Using polling engine: epoll1\nD0921 20:51:18.682101858      13 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0921 20:51:18.682113026      13 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0921 20:51:18.682120316      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0921 20:51:18.682128825      13 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0921 20:51:18.682131920      13 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0921 20:51:18.682134693      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD0921 20:51:18.682158243      13 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0921 20:51:18.682172949      13 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD0921 20:51:18.682188737      13 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0921 20:51:18.682212096      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0921 20:51:18.682219406      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0921 20:51:18.682222507      13 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0921 20:51:18.682226050      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0921 20:51:18.682228973      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0921 20:51:18.682231979      13 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0921 20:51:18.682235223      13 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD0921 20:51:18.682263466      13 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI0921 20:51:18.684204866      13 ev_epoll1_linux.cc:359]               grpc epoll fd: 62\nI0921 20:51:18.707835535      13 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI0921 20:51:18.711357250     109 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI0921 20:51:18.711421243     109 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0921 20:51:18.716947271      13 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-09-21T20:51:18.716930291+00:00\", grpc_status:2}\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/contradictory-my-dear-watson/sample_submission.csv\n/kaggle/input/contradictory-my-dear-watson/train.csv\n/kaggle/input/contradictory-my-dear-watson/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Set up the TPU","metadata":{}},{"cell_type":"code","source":"try:\n  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # This is TPU detection\n  tf.config.experimental_connect_to_cluster(tpu)\n  tf.tpu.experimental.initialize_tpu_system(tpu)\n  strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError:\n  strategy = tf.distribute.get_strategy() #For CPU and/or single GPU\n  print(f'Number of replicas: {strategy.num_replicas_in_sync}')","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:51:32.173263Z","iopub.execute_input":"2024-09-21T20:51:32.174537Z","iopub.status.idle":"2024-09-21T20:51:41.456099Z","shell.execute_reply.started":"2024-09-21T20:51:32.174495Z","shell.execute_reply":"2024-09-21T20:51:41.455237Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1726951896.511544      13 service.cc:145] XLA service 0x5bcfdf92d600 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1726951896.511600      13 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1726951896.511605      13 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1726951896.511608      13 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1726951896.511611      13 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1726951896.511613      13 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1726951896.511616      13 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1726951896.511619      13 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1726951896.511621      13 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the Data\n\n| Label | Meaning | \n| --- | --- | \n| 0 | entailment|\n| 1 | neutral|\n| 2 | contradiction|","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\ntest = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/test.csv')\n\ntrain.groupby('label').sample(2, random_state=1).style.hide(axis='index')","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:51:49.631165Z","iopub.execute_input":"2024-09-21T20:51:49.632393Z","iopub.status.idle":"2024-09-21T20:51:49.846585Z","shell.execute_reply.started":"2024-09-21T20:51:49.632325Z","shell.execute_reply":"2024-09-21T20:51:49.845733Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7f5582f43580>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_9f781\">\n  <thead>\n    <tr>\n      <th id=\"T_9f781_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n      <th id=\"T_9f781_level0_col1\" class=\"col_heading level0 col1\" >premise</th>\n      <th id=\"T_9f781_level0_col2\" class=\"col_heading level0 col2\" >hypothesis</th>\n      <th id=\"T_9f781_level0_col3\" class=\"col_heading level0 col3\" >lang_abv</th>\n      <th id=\"T_9f781_level0_col4\" class=\"col_heading level0 col4\" >language</th>\n      <th id=\"T_9f781_level0_col5\" class=\"col_heading level0 col5\" >label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_9f781_row0_col0\" class=\"data row0 col0\" >14fa262750</td>\n      <td id=\"T_9f781_row0_col1\" class=\"data row0 col1\" >The almost midtown Massabielle quarter (faubourg de Massabielle), is sometimes described as the most picturesque in the city.</td>\n      <td id=\"T_9f781_row0_col2\" class=\"data row0 col2\" >The Massabielle quarter is considered the most photogenic.</td>\n      <td id=\"T_9f781_row0_col3\" class=\"data row0 col3\" >en</td>\n      <td id=\"T_9f781_row0_col4\" class=\"data row0 col4\" >English</td>\n      <td id=\"T_9f781_row0_col5\" class=\"data row0 col5\" >0</td>\n    </tr>\n    <tr>\n      <td id=\"T_9f781_row1_col0\" class=\"data row1 col0\" >b20c96d26b</td>\n      <td id=\"T_9f781_row1_col1\" class=\"data row1 col1\" >Wanaweza pia kuwa wazuri baada ya kufunzwa.</td>\n      <td id=\"T_9f781_row1_col2\" class=\"data row1 col2\" >Wanapopata mafunzo wanaweza kuwa wazuri kabisa</td>\n      <td id=\"T_9f781_row1_col3\" class=\"data row1 col3\" >sw</td>\n      <td id=\"T_9f781_row1_col4\" class=\"data row1 col4\" >Swahili</td>\n      <td id=\"T_9f781_row1_col5\" class=\"data row1 col5\" >0</td>\n    </tr>\n    <tr>\n      <td id=\"T_9f781_row2_col0\" class=\"data row2 col0\" >07e55edb23</td>\n      <td id=\"T_9f781_row2_col1\" class=\"data row2 col1\" >добре, добре, не преминавайте през всичко възможно</td>\n      <td id=\"T_9f781_row2_col2\" class=\"data row2 col2\" >Можете просто да ми кажете края на историята.</td>\n      <td id=\"T_9f781_row2_col3\" class=\"data row2 col3\" >bg</td>\n      <td id=\"T_9f781_row2_col4\" class=\"data row2 col4\" >Bulgarian</td>\n      <td id=\"T_9f781_row2_col5\" class=\"data row2 col5\" >1</td>\n    </tr>\n    <tr>\n      <td id=\"T_9f781_row3_col0\" class=\"data row3 col0\" >b2e5c736a2</td>\n      <td id=\"T_9f781_row3_col1\" class=\"data row3 col1\" >.Bằng cách tiếp cận các học sinh không tiếp cận được thông qua trường học và các tổ chức cộng đồng khác.</td>\n      <td id=\"T_9f781_row3_col2\" class=\"data row3 col2\" >Các sinh viên  đạt  sẽ mãi mãi biết ơn</td>\n      <td id=\"T_9f781_row3_col3\" class=\"data row3 col3\" >vi</td>\n      <td id=\"T_9f781_row3_col4\" class=\"data row3 col4\" >Vietnamese</td>\n      <td id=\"T_9f781_row3_col5\" class=\"data row3 col5\" >1</td>\n    </tr>\n    <tr>\n      <td id=\"T_9f781_row4_col0\" class=\"data row4 col0\" >3673d73972</td>\n      <td id=\"T_9f781_row4_col1\" class=\"data row4 col1\" >Since the mid 1990s, aggregate household wealth has swelled relative to disposable personal income, largely due to increases in the market value of households' existing assets (see figure 1.2).</td>\n      <td id=\"T_9f781_row4_col2\" class=\"data row4 col2\" >Aggregate household wealth has plummeted since the 1990s as household assets have steadily decreased.</td>\n      <td id=\"T_9f781_row4_col3\" class=\"data row4 col3\" >en</td>\n      <td id=\"T_9f781_row4_col4\" class=\"data row4 col4\" >English</td>\n      <td id=\"T_9f781_row4_col5\" class=\"data row4 col5\" >2</td>\n    </tr>\n    <tr>\n      <td id=\"T_9f781_row5_col0\" class=\"data row5 col0\" >5e37605f1d</td>\n      <td id=\"T_9f781_row5_col1\" class=\"data row5 col1\" >Sit down, will you?\" Tuppence sat down on the chair facing him.</td>\n      <td id=\"T_9f781_row5_col2\" class=\"data row5 col2\" >He told Tuppence to get out. </td>\n      <td id=\"T_9f781_row5_col3\" class=\"data row5 col3\" >en</td>\n      <td id=\"T_9f781_row5_col4\" class=\"data row5 col4\" >English</td>\n      <td id=\"T_9f781_row5_col5\" class=\"data row5 col5\" >2</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"train.hypothesis.str.split()","metadata":{}},{"cell_type":"markdown","source":"## Prepare Data for Input\n\nWe'll use a pretrained BERT model from HuggingFace.\n\nFirst, we'll download the tokenizer.\n\nTokenizers turn sequences of words into arrays of numbers.","metadata":{}},{"cell_type":"code","source":"model_name = 'bert-base-multilingual-cased'\n\n# We imported BertTokenizer from transformers\ntokenizer = BertTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:53:29.244368Z","iopub.execute_input":"2024-09-21T20:53:29.245354Z","iopub.status.idle":"2024-09-21T20:53:30.535052Z","shell.execute_reply.started":"2024-09-21T20:53:29.245306Z","shell.execute_reply":"2024-09-21T20:53:30.533909Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Let's look at an example tokenization","metadata":{}},{"cell_type":"code","source":"def encode_sentence(sentence):\n  # This is using the BERT Tokenizer that we just downloaded to generate tokens\n  # So the sentence \"I love machine learning\" becomes\n  # ['I', 'love', 'machine', 'learning', '!']\n  tokens = list(tokenizer.tokenize(sentence))\n\n  # Adding the separator token\n  tokens.append('[SEP]')\n\n  # This is using the BERT Tokenizer to convert the tokens to unique integers\n  # So  ['I', 'love', 'machine', 'learning', '!'] becomes \n  # [146, 16138, 21432, 26901, 106]\n  return tokenizer.convert_tokens_to_ids(tokens)\n\nencode_sentence('I love machine learning')","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:53:32.591622Z","iopub.execute_input":"2024-09-21T20:53:32.592307Z","iopub.status.idle":"2024-09-21T20:53:32.598932Z","shell.execute_reply.started":"2024-09-21T20:53:32.592268Z","shell.execute_reply":"2024-09-21T20:53:32.598053Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[146, 16138, 21432, 26901, 102]"},"metadata":{}}]},{"cell_type":"code","source":"encode_sentence('I LOVE MACHINE LEARNING')","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:53:33.841892Z","iopub.execute_input":"2024-09-21T20:53:33.842248Z","iopub.status.idle":"2024-09-21T20:53:33.848177Z","shell.execute_reply.started":"2024-09-21T20:53:33.842217Z","shell.execute_reply":"2024-09-21T20:53:33.847239Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[146, 52734, 71008, 108880, 93280, 84977, 52188, 52898, 34065, 102]"},"metadata":{}}]},{"cell_type":"markdown","source":"BERT requires three inputs:\n* input word IDs (what you see above)\n* input masks\n* input type IDs\n\nThese allow the model to know that the premise and hypothesis are distinct sentences and to ignore any padding from the tokenizer.\n\nA `[CLS]` token is used to denote the beginning of the inputs and a `[SEP]` token is used to separate the premise and hypothesis.\n\nWe also need to pad all of the inputs to be the same size.\n\nYou can read more about BERT inputs at HuggingFace.\n\nNow we can encode all premise/hypothesis pairs for input into BERT.","metadata":{}},{"cell_type":"code","source":"train.hypothesis.add(train.premise).apply(encode_sentence).apply(len).describe()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:54:58.617229Z","iopub.execute_input":"2024-09-21T20:54:58.617884Z","iopub.status.idle":"2024-09-21T20:55:05.456726Z","shell.execute_reply.started":"2024-09-21T20:54:58.617851Z","shell.execute_reply":"2024-09-21T20:55:05.455824Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"count    12120.000000\nmean        46.483993\nstd         23.291278\nmin          2.000000\n25%         30.000000\n50%         43.000000\n75%         59.000000\nmax        257.000000\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"max_len=75\n\ndef bert_encode(hypotheses, premises, tokenizer, max_len):\n\n  num_examples = len(hypotheses)\n\n  # Encode the input sentences and convert the results to tensors\n  hypoth_tensors = tf.ragged.constant(\n      [encode_sentence(s) for s in np.array(hypotheses)]\n  )\n\n  premise_tensors = tf.ragged.constant(\n      [encode_sentence(s) for s in np.array(premises)]\n  )\n\n  # Create the appropriate number of start tokens and then encode them\n  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])] * num_examples\n\n  # Create the input by combining the start token, the hypothesis, and the\n  # premise. (Keep in mind that the separator token was added by the \n  # encode_sentences function.)\n  # Don't forget to set the axis because the default is a vertical stack.\n  input_word_ids = tf.concat([cls, hypoth_tensors, premise_tensors], axis=1)\n\n  # The input mask is all ones (pay attention to everything?)\n  input_mask = tf.ones_like(input_word_ids).to_tensor(\n          shape=[input_word_ids.shape[0], max_len])\n\n  # The type IDs are all zeros? Why?\n  type_cls=tf.zeros_like(cls)\n  type_hypoth = tf.zeros_like(hypoth_tensors)\n  type_premise = tf.ones_like(premise_tensors)\n  input_type_ids = tf.concat([type_cls, type_hypoth, type_premise], axis=1)\\\n    .to_tensor(\n          shape=[input_word_ids.shape[0], max_len])\n\n  # Combine all inputs into a dictionary\n  inputs = {\n      'input_word_ids': input_word_ids.to_tensor(\n          shape=[input_word_ids.shape[0], max_len]),\n      'input_mask': input_mask,\n      'input_type_ids': input_type_ids\n  }\n\n  return inputs\n\nbert_encode(\n    train.head(2).hypothesis.values,\n    train.head(2).premise.values,\n    tokenizer,\n    max_len\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:56:17.663385Z","iopub.execute_input":"2024-09-21T20:56:17.664161Z","iopub.status.idle":"2024-09-21T20:56:17.722123Z","shell.execute_reply.started":"2024-09-21T20:56:17.664125Z","shell.execute_reply":"2024-09-21T20:56:17.721223Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'input_word_ids': <tf.Tensor: shape=(2, 75), dtype=int32, numpy=\n array([[  101, 10117, 23123, 14628, 10106, 10105, 63313, 10309, 14499,\n         14229, 10169, 11762, 61565, 10106, 21133,   119,   102, 10111,\n         11762, 61565, 10309, 14289, 10106, 29659, 12141, 10105, 63313,\n         23123,   119,   102,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0],\n        [  101, 46184, 15647, 10301, 10472, 63505, 10114, 11424, 10135,\n         11762, 17850,   119,   102, 13252, 10301, 17850, 10189, 11951,\n           191, 34189, 10284, 10169, 10106, 18194, 15647, 10108, 13255,\n         84459,   117, 10833, 12415,   119,   102,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0]], dtype=int32)>,\n 'input_mask': <tf.Tensor: shape=(2, 75), dtype=int32, numpy=\n array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>,\n 'input_type_ids': <tf.Tensor: shape=(2, 75), dtype=int32, numpy=\n array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"},"metadata":{}}]},{"cell_type":"code","source":"train_input = bert_encode(\n    train.hypothesis.values,\n    train.premise.values,\n    tokenizer,\n    max_len\n)\n\ntest_input = bert_encode(\n    test.hypothesis.values,\n    test.premise.values,\n    tokenizer,\n    max_len\n)\n\nprint('Input data prepared for modeling')","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:56:36.695694Z","iopub.execute_input":"2024-09-21T20:56:36.696369Z","iopub.status.idle":"2024-09-21T20:56:48.436319Z","shell.execute_reply.started":"2024-09-21T20:56:36.696335Z","shell.execute_reply":"2024-09-21T20:56:48.435087Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Input data prepared for modeling\n","output_type":"stream"}]},{"cell_type":"code","source":"# We can see the encoding of the first test sentence here like this\ntest_input['input_word_ids'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:56:52.871965Z","iopub.execute_input":"2024-09-21T20:56:52.873096Z","iopub.status.idle":"2024-09-21T20:56:52.881125Z","shell.execute_reply.started":"2024-09-21T20:56:52.873059Z","shell.execute_reply":"2024-09-21T20:56:52.880157Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(75,), dtype=int32, numpy=\narray([  101, 11076, 16577, 10691,   787, 26649, 40634, 59360, 50717,\n       21735, 18779, 47238,   117, 13244, 22887, 12710,   829, 32245,\n       11722, 85408, 10691, 69883, 23172, 13378, 10916, 11689, 12427,\n       13141,   788, 10673, 17571,   119,   102,   764, 28744,   752,\n       11076, 16577,   752, 10748, 67499, 10961,   752,   834, 82397,\n       17317, 11242,   752, 11076, 16161,   752, 11076, 16161,   752,\n       11363, 13244, 22887, 76528,   829, 32245, 11722, 85408, 10691,\n       86325, 77970, 10429, 10691, 12995, 11689,   764, 28744, 13378,\n       13244, 29847,   774], dtype=int32)>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Create the Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n  # Load the BERT model from TensorFlow Hub\n  bert_encoder = TFBertModel.from_pretrained(model_name)\n\n  # Create the input layers for the model\n  input_word_ids = tf.keras.Input(shape=(max_len,),\n                                  dtype=tf.int32,\n                                  name='input_word_ids')\n  \n  input_mask = tf.keras.Input(shape=(max_len,),\n                              dtype=tf.int32,\n                              name='input_mask')\n  \n  input_type_ids = tf.keras.Input(shape=(max_len,),\n                                  dtype=tf.int32,\n                                  name='input_type_ids')\n  \n  # Encode the input sentences\n  # This creates a tensor of shape=(None, max_len, 768)\n  embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]\n\n  # Specify the output\n  # This creates a tensor of shape=(None, 3) (since we have three classes?)\n  output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0, :])\n\n  # Create the model given the inputs and outputs\n  model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids],\n                         outputs=output)\n  \n  # Compile the model based on accuracy metric\n  model.compile(tf.keras.optimizers.Adam(learning_rate=1e-5),\n                loss='sparse_categorical_crossentropy',\n                metrics=['accuracy'])\n  \n  return model\n\n# Instantiate the model and print summary\nwith strategy.scope():\n  model = build_model()\n  model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-21T20:57:28.613356Z","iopub.execute_input":"2024-09-21T20:57:28.614052Z","iopub.status.idle":"2024-09-21T20:57:59.903436Z","shell.execute_reply.started":"2024-09-21T20:57:28.614004Z","shell.execute_reply":"2024-09-21T20:57:59.902503Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"I0000 00:00:1726952252.409548      13 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_word_ids (InputLayer  [(None, 75)]                 0         []                            \n )                                                                                                \n                                                                                                  \n input_mask (InputLayer)     [(None, 75)]                 0         []                            \n                                                                                                  \n input_type_ids (InputLayer  [(None, 75)]                 0         []                            \n )                                                                                                \n                                                                                                  \n tf_bert_model (TFBertModel  TFBaseModelOutputWithPooli   1778534   ['input_word_ids[0][0]',      \n )                           ngAndCrossAttentions(last_   40         'input_mask[0][0]',          \n                             hidden_state=(None, 75, 76              'input_type_ids[0][0]']      \n                             8),                                                                  \n                              pooler_output=(None, 768)                                           \n                             , past_key_values=None, hi                                           \n                             dden_states=None, attentio                                           \n                             ns=None, cross_attentions=                                           \n                             None)                                                                \n                                                                                                  \n tf.__operators__.getitem (  (None, 768)                  0         ['tf_bert_model[0][0]']       \n SlicingOpLambda)                                                                                 \n                                                                                                  \n dense (Dense)               (None, 3)                    2307      ['tf.__operators__.getitem[0][\n                                                                    0]']                          \n                                                                                                  \n==================================================================================================\nTotal params: 177855747 (678.47 MB)\nTrainable params: 177855747 (678.47 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train the Model","metadata":{}},{"cell_type":"code","source":"model.fit(train_input,\n          train.label.values,\n          validation_split=0.2,\n          epochs=2,\n          verbose=1,\n          batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T15:47:27.295051Z","iopub.execute_input":"2024-09-21T15:47:27.295491Z","iopub.status.idle":"2024-09-21T17:27:53.537063Z","shell.execute_reply.started":"2024-09-21T15:47:27.295449Z","shell.execute_reply":"2024-09-21T17:27:53.530136Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/2\n152/152 [==============================] - 3097s 20s/step - loss: 1.0430 - accuracy: 0.4500 - val_loss: 0.9270 - val_accuracy: 0.5664\nEpoch 2/2\n152/152 [==============================] - 2929s 19s/step - loss: 0.8369 - accuracy: 0.6231 - val_loss: 0.8849 - val_accuracy: 0.5969\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7d8ac5809630>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Make Predictions on the Test Set","metadata":{}},{"cell_type":"code","source":"class_probabilities = model.predict(test_input)\n\npredictions = class_probabilities.argmax(axis=-1)\n\nsubmission = pd.DataFrame({'id': test.id, 'prediction': predictions})\n\nsubmission.to_csv(\n    'submission.csv',\n    index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T17:27:53.541161Z","iopub.execute_input":"2024-09-21T17:27:53.541722Z"},"trusted":true},"execution_count":null,"outputs":[]}]}