{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Contradictory, My Dear Watson\n\nCan machines determine the relationships between sentences?\n\nGiven two sentences, there are three ways they could be related:\n* one could entail the other\n* one could contradict the other\n* they could be unrelated","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom transformers import BertTokenizer, TFBertModel\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-23T08:26:49.279779Z","iopub.execute_input":"2024-09-23T08:26:49.280033Z","iopub.status.idle":"2024-09-23T08:27:26.274484Z","shell.execute_reply.started":"2024-09-23T08:26:49.280007Z","shell.execute_reply":"2024-09-23T08:27:26.273748Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nWARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1727080037.323303      12 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD0923 08:27:17.331401505      12 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD0923 08:27:17.331416066      12 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD0923 08:27:17.331419382      12 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD0923 08:27:17.331421695      12 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD0923 08:27:17.331424065      12 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD0923 08:27:17.331426338      12 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD0923 08:27:17.331428604      12 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD0923 08:27:17.331430780      12 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD0923 08:27:17.331432950      12 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD0923 08:27:17.331435114      12 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD0923 08:27:17.331437370      12 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD0923 08:27:17.331439545      12 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD0923 08:27:17.331441715      12 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD0923 08:27:17.331443876      12 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD0923 08:27:17.331446044      12 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD0923 08:27:17.331448185      12 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD0923 08:27:17.331450501      12 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD0923 08:27:17.331452756      12 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD0923 08:27:17.331454930      12 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD0923 08:27:17.331457130      12 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD0923 08:27:17.331459298      12 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD0923 08:27:17.331461465      12 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD0923 08:27:17.331463767      12 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD0923 08:27:17.331465988      12 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD0923 08:27:17.331468107      12 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD0923 08:27:17.331470238      12 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD0923 08:27:17.331472448      12 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD0923 08:27:17.331474640      12 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD0923 08:27:17.331476910      12 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD0923 08:27:17.331480122      12 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD0923 08:27:17.331482382      12 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD0923 08:27:17.331484734      12 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD0923 08:27:17.331487001      12 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD0923 08:27:17.331489188      12 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD0923 08:27:17.331491311      12 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD0923 08:27:17.331493486      12 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD0923 08:27:17.331495549      12 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD0923 08:27:17.331497697      12 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD0923 08:27:17.331499907      12 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD0923 08:27:17.331502120      12 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD0923 08:27:17.331504251      12 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD0923 08:27:17.331506380      12 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD0923 08:27:17.331508545      12 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD0923 08:27:17.331510734      12 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD0923 08:27:17.331512982      12 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI0923 08:27:17.331681293      12 ev_epoll1_linux.cc:123]               grpc epoll fd: 60\nD0923 08:27:17.331693234      12 ev_posix.cc:113]                      Using polling engine: epoll1\nD0923 08:27:17.342907093      12 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0923 08:27:17.342919917      12 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0923 08:27:17.342928188      12 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0923 08:27:17.342931796      12 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0923 08:27:17.342934940      12 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0923 08:27:17.342937958      12 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD0923 08:27:17.342963284      12 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0923 08:27:17.342979259      12 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD0923 08:27:17.342996122      12 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0923 08:27:17.343021417      12 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0923 08:27:17.343029372      12 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0923 08:27:17.343032940      12 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0923 08:27:17.343037496      12 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0923 08:27:17.343040890      12 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0923 08:27:17.343048456      12 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0923 08:27:17.343052116      12 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD0923 08:27:17.343082788      12 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI0923 08:27:17.345285205      12 ev_epoll1_linux.cc:359]               grpc epoll fd: 62\nI0923 08:27:17.359587024      12 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI0923 08:27:17.362916287     104 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI0923 08:27:17.362962642     104 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0923 08:27:17.368793581      12 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-09-23T08:27:17.368779159+00:00\", grpc_status:2}\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/contradictory-my-dear-watson/sample_submission.csv\n/kaggle/input/contradictory-my-dear-watson/train.csv\n/kaggle/input/contradictory-my-dear-watson/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Set up the TPU","metadata":{}},{"cell_type":"code","source":"try:\n  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # This is TPU detection\n  tf.config.experimental_connect_to_cluster(tpu)\n  tf.tpu.experimental.initialize_tpu_system(tpu)\n  strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError:\n  strategy = tf.distribute.get_strategy() #For CPU and/or single GPU\n  print(f'Number of replicas: {strategy.num_replicas_in_sync}')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:27:45.609456Z","iopub.execute_input":"2024-09-23T08:27:45.610457Z","iopub.status.idle":"2024-09-23T08:27:57.342040Z","shell.execute_reply.started":"2024-09-23T08:27:45.610414Z","shell.execute_reply":"2024-09-23T08:27:57.341267Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1727080072.655029      12 service.cc:145] XLA service 0x5b242dd5c1e0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1727080072.655087      12 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1727080072.655092      12 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1727080072.655096      12 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1727080072.655099      12 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1727080072.655102      12 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1727080072.655105      12 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1727080072.655107      12 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1727080072.655110      12 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the Data\n\n| Label | Meaning | \n| --- | --- | \n| 0 | entailment|\n| 1 | neutral|\n| 2 | contradiction|","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_raw = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\ntest = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/test.csv')\n\ntrain, valid = train_test_split(train_raw,\n                                test_size=0.2,\n                                random_state=0,\n                                stratify=train_raw.lang_abv)\n\ntrain\\\n    .loc[lambda df: df.lang_abv.eq('en')]\\\n    .groupby('label')\\\n    .sample(2, random_state=1)\\\n    [['premise', 'hypothesis', 'label']]\\\n    .style.hide(axis='index')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:27:57.343294Z","iopub.execute_input":"2024-09-23T08:27:57.343531Z","iopub.status.idle":"2024-09-23T08:27:57.576511Z","shell.execute_reply.started":"2024-09-23T08:27:57.343505Z","shell.execute_reply":"2024-09-23T08:27:57.575699Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x78c33c46a170>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_820ac\">\n  <thead>\n    <tr>\n      <th id=\"T_820ac_level0_col0\" class=\"col_heading level0 col0\" >premise</th>\n      <th id=\"T_820ac_level0_col1\" class=\"col_heading level0 col1\" >hypothesis</th>\n      <th id=\"T_820ac_level0_col2\" class=\"col_heading level0 col2\" >label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_820ac_row0_col0\" class=\"data row0 col0\" >so are can i just ask you are you Canadian</td>\n      <td id=\"T_820ac_row0_col1\" class=\"data row0 col1\" >Are you from Canada?</td>\n      <td id=\"T_820ac_row0_col2\" class=\"data row0 col2\" >0</td>\n    </tr>\n    <tr>\n      <td id=\"T_820ac_row1_col0\" class=\"data row1 col0\" >The first, reached from Luxor, is Esna, 54 km (33 miles) by road.</td>\n      <td id=\"T_820ac_row1_col1\" class=\"data row1 col1\" >Esna is located 54km away from Luxor.</td>\n      <td id=\"T_820ac_row1_col2\" class=\"data row1 col2\" >0</td>\n    </tr>\n    <tr>\n      <td id=\"T_820ac_row2_col0\" class=\"data row2 col0\" >The association's mission is to reduce the incidence of fraud and white-collar crime through prevention and education.</td>\n      <td id=\"T_820ac_row2_col1\" class=\"data row2 col1\" >The association hopes people will not steal someone's identity.</td>\n      <td id=\"T_820ac_row2_col2\" class=\"data row2 col2\" >1</td>\n    </tr>\n    <tr>\n      <td id=\"T_820ac_row3_col0\" class=\"data row3 col0\" >yeah well are you you with TI</td>\n      <td id=\"T_820ac_row3_col1\" class=\"data row3 col1\" >TI is the tourism international society.</td>\n      <td id=\"T_820ac_row3_col2\" class=\"data row3 col2\" >1</td>\n    </tr>\n    <tr>\n      <td id=\"T_820ac_row4_col0\" class=\"data row4 col0\" >Despite protests by preservationists, there was little alternative.</td>\n      <td id=\"T_820ac_row4_col1\" class=\"data row4 col1\" >There were various alternatives and one that was appeasing to everyone was implemented.</td>\n      <td id=\"T_820ac_row4_col2\" class=\"data row4 col2\" >2</td>\n    </tr>\n    <tr>\n      <td id=\"T_820ac_row5_col0\" class=\"data row5 col0\" >Participation in the rulemaking process requires (1) the public to be aware of opportunities to participate and (2) systems that will allow agencies to receive comments in an efficient and effective manner.</td>\n      <td id=\"T_820ac_row5_col1\" class=\"data row5 col1\" >The public need not be made aware of any opportunities for rulemaking processes.</td>\n      <td id=\"T_820ac_row5_col2\" class=\"data row5 col2\" >2</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Prepare Data for Input\n\nWe'll use a pretrained BERT model from HuggingFace.\n\nFirst, we'll download the tokenizer.\n\nTokenizers turn sequences of words into arrays of numbers.","metadata":{}},{"cell_type":"code","source":"model_name = 'bert-base-multilingual-cased'\n\n# We imported BertTokenizer from transformers\ntokenizer = BertTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:27:57.577587Z","iopub.execute_input":"2024-09-23T08:27:57.578163Z","iopub.status.idle":"2024-09-23T08:27:59.831428Z","shell.execute_reply.started":"2024-09-23T08:27:57.578126Z","shell.execute_reply":"2024-09-23T08:27:59.830302Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Let's look at an example tokenization","metadata":{}},{"cell_type":"code","source":"def encode_sentence(sentence):\n  # This is using the BERT Tokenizer that we just downloaded to generate tokens\n  # So the sentence \"I love machine learning\" becomes\n  # ['I', 'love', 'machine', 'learning', '!']\n  tokens = list(tokenizer.tokenize(sentence))\n\n  # Adding the separator token\n  tokens.append('[SEP]')\n\n  # This is using the BERT Tokenizer to convert the tokens to unique integers\n  # So  ['I', 'love', 'machine', 'learning', '!'] becomes \n  # [146, 16138, 21432, 26901, 106]\n  return tokenizer.convert_tokens_to_ids(tokens)\n\nencode_sentence('I love machine learning')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:27:59.833453Z","iopub.execute_input":"2024-09-23T08:27:59.833756Z","iopub.status.idle":"2024-09-23T08:27:59.840558Z","shell.execute_reply.started":"2024-09-23T08:27:59.833729Z","shell.execute_reply":"2024-09-23T08:27:59.839643Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[146, 16138, 21432, 26901, 102]"},"metadata":{}}]},{"cell_type":"code","source":"encode_sentence('I LOVE MACHINE LEARNING')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:27:59.841520Z","iopub.execute_input":"2024-09-23T08:27:59.841754Z","iopub.status.idle":"2024-09-23T08:27:59.854279Z","shell.execute_reply.started":"2024-09-23T08:27:59.841731Z","shell.execute_reply":"2024-09-23T08:27:59.853475Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[146, 52734, 71008, 108880, 93280, 84977, 52188, 52898, 34065, 102]"},"metadata":{}}]},{"cell_type":"markdown","source":"BERT requires three inputs:\n* input word IDs (what you see above)\n* input masks\n* input type IDs\n\nThese allow the model to know that the premise and hypothesis are distinct sentences and to ignore any padding from the tokenizer.\n\nA `[CLS]` token is used to denote the beginning of the inputs and a `[SEP]` token is used to separate the premise and hypothesis.\n\nWe also need to pad all of the inputs to be the same size.\n\nYou can read more about BERT inputs at HuggingFace.\n\nNow we can encode all premise/hypothesis pairs for input into BERT.\n\n### How long are the sentences?","metadata":{}},{"cell_type":"code","source":"train\\\n    .hypothesis.add(train.premise)\\\n    .apply(encode_sentence)\\\n    .apply(len)\\\n    .describe()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:27:59.855233Z","iopub.execute_input":"2024-09-23T08:27:59.855469Z","iopub.status.idle":"2024-09-23T08:28:05.516349Z","shell.execute_reply.started":"2024-09-23T08:27:59.855445Z","shell.execute_reply":"2024-09-23T08:28:05.515179Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"count    9696.000000\nmean       46.374587\nstd        23.264591\nmin         2.000000\n25%        30.000000\n50%        43.000000\n75%        59.000000\nmax       257.000000\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"max_len=75\n\ndef bert_encode(hypotheses, premises, tokenizer, max_len):\n\n  num_examples = len(hypotheses)\n\n  # Encode the input sentences and convert the results to tensors\n  hypoth_tensors = tf.ragged.constant(\n      [encode_sentence(s) for s in np.array(hypotheses)]\n  )\n\n  premise_tensors = tf.ragged.constant(\n      [encode_sentence(s) for s in np.array(premises)]\n  )\n\n  # Create the appropriate number of start tokens and then encode them\n  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])] * num_examples\n\n  # Create the input by combining the start token, the hypothesis, and the\n  # premise. (Keep in mind that the separator token was added by the \n  # encode_sentences function.)\n  # Don't forget to set the axis because the default is a vertical stack.\n  input_word_ids = tf.concat([cls, hypoth_tensors, premise_tensors], axis=1)\n\n  # The input mask is all ones (pay attention to everything?)\n  input_mask = tf.ones_like(input_word_ids).to_tensor(\n          shape=[input_word_ids.shape[0], max_len])\n\n  # The type IDs are all zeros? Why?\n  type_cls=tf.zeros_like(cls)\n  type_hypoth = tf.zeros_like(hypoth_tensors)\n  type_premise = tf.ones_like(premise_tensors)\n  input_type_ids = tf.concat([type_cls, type_hypoth, type_premise], axis=1)\\\n    .to_tensor(\n          shape=[input_word_ids.shape[0], max_len])\n\n  # Combine all inputs into a dictionary\n  inputs = {\n      'input_word_ids': input_word_ids.to_tensor(\n          shape=[input_word_ids.shape[0], max_len]),\n      'input_mask': input_mask,\n      'input_type_ids': input_type_ids\n  }\n\n  return inputs\n\nbert_encode(\n    train.head(2).hypothesis.values,\n    train.head(2).premise.values,\n    tokenizer,\n    max_len\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:28:05.517591Z","iopub.execute_input":"2024-09-23T08:28:05.517972Z","iopub.status.idle":"2024-09-23T08:28:05.578071Z","shell.execute_reply.started":"2024-09-23T08:28:05.517917Z","shell.execute_reply":"2024-09-23T08:28:05.576881Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'input_word_ids': <tf.Tensor: shape=(2, 75), dtype=int32, numpy=\n array([[   101,  40690,    117,    146,  21852,    119,    102,  10657,\n            117,    146,  16938,    112,    188,  21852,    119,    102,\n              0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0],\n        [   101,  39301,    189,  12577,  77008,  10343,  11471,  15694,\n          15673,  10113,  10339,  87051,  10116,  10549,  10440,  15694,\n         106156,  29175,    119,    102,  77056,  68192,  62310,  10113,\n          11735,  19402,  11465,  27919,  15694,  28726,  10465,  10637,\n          10132,  10133,    117,  58671,  10153,  61478,  14540,  10113,\n          79782,  10921,  10339,  33208,  10330,  11471,  86851,  11090,\n          14266,  15694,  15673,  10113,  10339,  87051,  10116,  10549,\n          10440,  13743,  15688,  20578,  10921,  10549,  48350,  10703,\n          68257,    119,    102,      0,      0,      0,      0,      0,\n              0,      0,      0]], dtype=int32)>,\n 'input_mask': <tf.Tensor: shape=(2, 75), dtype=int32, numpy=\n array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>,\n 'input_type_ids': <tf.Tensor: shape=(2, 75), dtype=int32, numpy=\n array([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"},"metadata":{}}]},{"cell_type":"code","source":"train_input = bert_encode(\n    train.hypothesis.values,\n    train.premise.values,\n    tokenizer,\n    max_len\n)\n\nvalid_input = bert_encode(\n    valid.hypothesis.values,\n    valid.premise.values,\n    tokenizer,\n    max_len\n)\n\ntest_input = bert_encode(\n    test.hypothesis.values,\n    test.premise.values,\n    tokenizer,\n    max_len\n)\n\nprint('Input data prepared for modeling')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:28:05.579393Z","iopub.execute_input":"2024-09-23T08:28:05.580278Z","iopub.status.idle":"2024-09-23T08:28:17.468157Z","shell.execute_reply.started":"2024-09-23T08:28:05.580241Z","shell.execute_reply":"2024-09-23T08:28:17.467073Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Input data prepared for modeling\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train.hypothesis.iloc[0], train.premise.iloc[0], train.label.iloc[0])\n\n# We can see the encoding of the first train sentence here like this\ntrain_input['input_word_ids'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:28:17.469346Z","iopub.execute_input":"2024-09-23T08:28:17.469625Z","iopub.status.idle":"2024-09-23T08:28:17.478126Z","shell.execute_reply.started":"2024-09-23T08:28:17.469599Z","shell.execute_reply":"2024-09-23T08:28:17.477269Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Yes, I know. No, I don't know.  2\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(75,), dtype=int32, numpy=\narray([  101, 40690,   117,   146, 21852,   119,   102, 10657,   117,\n         146, 16938,   112,   188, 21852,   119,   102,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0], dtype=int32)>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Create the Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n  # Load the BERT model from TensorFlow Hub\n  bert_encoder = TFBertModel.from_pretrained(model_name)\n\n  # Create the input layers for the model\n  input_word_ids = tf.keras.Input(shape=(max_len,),\n                                  dtype=tf.int32,\n                                  name='input_word_ids')\n  \n  input_mask = tf.keras.Input(shape=(max_len,),\n                              dtype=tf.int32,\n                              name='input_mask')\n  \n  input_type_ids = tf.keras.Input(shape=(max_len,),\n                                  dtype=tf.int32,\n                                  name='input_type_ids')\n  \n  # Encode the input sentences\n  # This creates a tensor of shape=(None, max_len, 768)\n  embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]\n\n  # Specify the output\n  # This creates a tensor of shape=(None, 3) (since we have three classes?)\n  output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0, :])\n\n  # Create the model given the inputs and outputs\n  model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids],\n                         outputs=output)\n  \n  # Compile the model based on accuracy metric\n  model.compile(tf.keras.optimizers.Adam(learning_rate=1e-5),\n                loss='sparse_categorical_crossentropy',\n                metrics=['accuracy'])\n  \n  return model\n\n# Instantiate the model and print summary\nwith strategy.scope():\n  model = build_model()\n  model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:28:17.480662Z","iopub.execute_input":"2024-09-23T08:28:17.480987Z","iopub.status.idle":"2024-09-23T08:28:48.238607Z","shell.execute_reply.started":"2024-09-23T08:28:17.480955Z","shell.execute_reply":"2024-09-23T08:28:48.237564Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"I0000 00:00:1727080099.919795      12 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_word_ids (InputLayer  [(None, 75)]                 0         []                            \n )                                                                                                \n                                                                                                  \n input_mask (InputLayer)     [(None, 75)]                 0         []                            \n                                                                                                  \n input_type_ids (InputLayer  [(None, 75)]                 0         []                            \n )                                                                                                \n                                                                                                  \n tf_bert_model (TFBertModel  TFBaseModelOutputWithPooli   1778534   ['input_word_ids[0][0]',      \n )                           ngAndCrossAttentions(last_   40         'input_mask[0][0]',          \n                             hidden_state=(None, 75, 76              'input_type_ids[0][0]']      \n                             8),                                                                  \n                              pooler_output=(None, 768)                                           \n                             , past_key_values=None, hi                                           \n                             dden_states=None, attentio                                           \n                             ns=None, cross_attentions=                                           \n                             None)                                                                \n                                                                                                  \n tf.__operators__.getitem (  (None, 768)                  0         ['tf_bert_model[0][0]']       \n SlicingOpLambda)                                                                                 \n                                                                                                  \n dense (Dense)               (None, 3)                    2307      ['tf.__operators__.getitem[0][\n                                                                    0]']                          \n                                                                                                  \n==================================================================================================\nTotal params: 177855747 (678.47 MB)\nTrainable params: 177855747 (678.47 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train the Model\n\nUse early stopping to control the number of epochs.","metadata":{}},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',  # You can change this to 'val_loss'\n    patience=3,              # Stop after 3 epochs with no improvement\n    restore_best_weights=True\n)\n\nmodel.fit(train_input,\n          train.label.values,\n          validation_data=(valid_input, valid.label.values),\n          epochs=50,\n          verbose=1,\n          batch_size=64,\n          callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:28:48.246287Z","iopub.execute_input":"2024-09-23T08:28:48.246527Z","iopub.status.idle":"2024-09-23T08:33:33.557249Z","shell.execute_reply.started":"2024-09-23T08:28:48.246503Z","shell.execute_reply":"2024-09-23T08:33:33.556196Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/50\nWARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","output_type":"stream"},{"name":"stdout","text":"WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","output_type":"stream"},{"name":"stdout","text":"WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","output_type":"stream"},{"name":"stdout","text":"WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n2024-09-23 08:29:47.542337: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\nI0000 00:00:1727080190.480385     828 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(570239134acc4e17:0:0), session_name()\nI0000 00:00:1727080222.439782     828 tpu_compile_op_common.cc:245] Compilation of 570239134acc4e17:0:0 with session name  took 31.959349092s and succeeded\nI0000 00:00:1727080222.524117     828 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(570239134acc4e17:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_18247264971753395072\", property.function_library_fingerprint = 11395093272996447256, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"8,75,;8,75,;8,75,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727080222.524168     828 tpu_compilation_cache_interface.cc:541] After adding entry for key 570239134acc4e17:0:0 with session_name  cache is 1 entries (192821515 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"151/152 [============================>.] - ETA: 0s - loss: 1.0117 - accuracy: 0.4849","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727080236.742013     838 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(e851ce6a469b54ca:0:0), session_name()\nI0000 00:00:1727080265.302001     838 tpu_compile_op_common.cc:245] Compilation of e851ce6a469b54ca:0:0 with session name  took 28.559943872s and succeeded\nI0000 00:00:1727080265.382128     838 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(e851ce6a469b54ca:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_18247264971753395072\", property.function_library_fingerprint = 11395093272996447256, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"4,75,;4,75,;4,75,;4,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727080265.382185     838 tpu_compilation_cache_interface.cc:541] After adding entry for key e851ce6a469b54ca:0:0 with session_name  cache is 2 entries (358493275 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"152/152 [==============================] - ETA: 0s - loss: 1.0105 - accuracy: 0.4857","output_type":"stream"},{"name":"stderr","text":"2024-09-23 08:31:16.108239: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\nI0000 00:00:1727080276.837876     803 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(1fb62e31b4ed8895:0:0), session_name()\nI0000 00:00:1727080280.537632     803 tpu_compile_op_common.cc:245] Compilation of 1fb62e31b4ed8895:0:0 with session name  took 3.69971833s and succeeded\nI0000 00:00:1727080280.566164     803 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(1fb62e31b4ed8895:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_test_function_13883616677987383626\", property.function_library_fingerprint = 12183572859597201306, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"8,75,;8,75,;8,75,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727080280.566197     803 tpu_compilation_cache_interface.cc:541] After adding entry for key 1fb62e31b4ed8895:0:0 with session_name  cache is 3 entries (404212135 bytes),  marked for eviction 0 entries (0 bytes).\nI0000 00:00:1727080281.366071     833 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(76db7a03af552710:0:0), session_name()\nI0000 00:00:1727080285.208487     833 tpu_compile_op_common.cc:245] Compilation of 76db7a03af552710:0:0 with session name  took 3.842382778s and succeeded\nI0000 00:00:1727080285.235236     833 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(76db7a03af552710:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_test_function_13883616677987383626\", property.function_library_fingerprint = 12183572859597201306, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"7,75,;7,75,;7,75,;7,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727080285.235274     833 tpu_compilation_cache_interface.cc:541] After adding entry for key 76db7a03af552710:0:0 with session_name  cache is 4 entries (449790984 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"152/152 [==============================] - 158s 425ms/step - loss: 1.0105 - accuracy: 0.4857 - val_loss: 0.8757 - val_accuracy: 0.5908\nEpoch 2/50\n152/152 [==============================] - 16s 107ms/step - loss: 0.8017 - accuracy: 0.6462 - val_loss: 0.8277 - val_accuracy: 0.6225\nEpoch 3/50\n152/152 [==============================] - 16s 106ms/step - loss: 0.6583 - accuracy: 0.7204 - val_loss: 0.8446 - val_accuracy: 0.6324\nEpoch 4/50\n152/152 [==============================] - 16s 106ms/step - loss: 0.5139 - accuracy: 0.7934 - val_loss: 0.9648 - val_accuracy: 0.6341\nEpoch 5/50\n152/152 [==============================] - 16s 108ms/step - loss: 0.3730 - accuracy: 0.8546 - val_loss: 1.0873 - val_accuracy: 0.6386\nEpoch 6/50\n152/152 [==============================] - 15s 101ms/step - loss: 0.2573 - accuracy: 0.9022 - val_loss: 1.2535 - val_accuracy: 0.6229\nEpoch 7/50\n152/152 [==============================] - 15s 102ms/step - loss: 0.1775 - accuracy: 0.9369 - val_loss: 1.3874 - val_accuracy: 0.6184\nEpoch 8/50\n152/152 [==============================] - 15s 101ms/step - loss: 0.1239 - accuracy: 0.9559 - val_loss: 1.7207 - val_accuracy: 0.6159\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x78c2801ba980>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Estimate accuracy on the test set","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nclass_probabilities = model.predict(valid_input)\n\npredictions_valid = class_probabilities.argmax(axis=-1)\n\naccuracy_score(y_true=valid.label.values,\n               y_pred=predictions_valid)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:36:59.322506Z","iopub.execute_input":"2024-09-23T08:36:59.323091Z","iopub.status.idle":"2024-09-23T08:37:01.353356Z","shell.execute_reply.started":"2024-09-23T08:36:59.323054Z","shell.execute_reply":"2024-09-23T08:37:01.352314Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"76/76 [==============================] - 2s 19ms/step\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0.6386138613861386"},"metadata":{}}]},{"cell_type":"markdown","source":"## Make Predictions on the Test Set","metadata":{}},{"cell_type":"code","source":"class_probabilities_test = model.predict(test_input)\n\npredictions_test = class_probabilities_test.argmax(axis=-1)\n\nsubmission = pd.DataFrame({'id': test.id, 'prediction': predictions_test})\n\nsubmission.to_csv(\n    'submission.csv',\n    index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:37:49.862212Z","iopub.execute_input":"2024-09-23T08:37:49.862625Z","iopub.status.idle":"2024-09-23T08:37:53.616756Z","shell.execute_reply.started":"2024-09-23T08:37:49.862590Z","shell.execute_reply":"2024-09-23T08:37:53.615640Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"163/163 [==============================] - 4s 19ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Hypothesis: The model performs better in English\n\nIf this is true, can we translate each sentence to English before classification?","metadata":{}},{"cell_type":"code","source":"valid\\\n    .assign(\n        pred = predictions_valid,\n        correct = lambda df: df.label.eq(df.pred)\n    )\\\n    .groupby('language')\\\n    .correct\\\n    .mean()\\\n    .sort_values()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:39:24.868081Z","iopub.execute_input":"2024-09-23T08:39:24.868480Z","iopub.status.idle":"2024-09-23T08:39:24.879273Z","shell.execute_reply.started":"2024-09-23T08:39:24.868446Z","shell.execute_reply":"2024-09-23T08:39:24.878224Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"language\nThai          0.472973\nGreek         0.546667\nRussian       0.546667\nUrdu          0.552632\nGerman        0.557143\nTurkish       0.571429\nSwahili       0.584416\nFrench        0.602564\nBulgarian     0.608696\nVietnamese    0.644737\nHindi         0.653333\nEnglish       0.668122\nChinese       0.670732\nSpanish       0.684932\nArabic        0.687500\nName: correct, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"Accuracy in English is not radically better than the overall accuracy.","metadata":{}},{"cell_type":"markdown","source":"## Look at some incorrect predictions","metadata":{}},{"cell_type":"code","source":"label_map = {\n    0: 'Entail',\n    1: 'Neutral',\n    2: 'Contra'\n}\n\nvalid\\\n    .assign(\n        _pred = predictions_valid,\n        correct = lambda df: df.label.eq(df._pred),\n        incorrect = lambda df: ~df.correct,\n        pred = lambda df: df._pred.replace(label_map),\n        label = lambda df: df.label.replace(label_map)\n    )\\\n    .groupby(['language', 'label', 'pred'], as_index=False)\\\n    .agg(\n        num_incorrect = ('incorrect', 'sum')\n    )\\\n    .sort_values(by=['num_incorrect'], ascending=False)\\\n    .loc[lambda df: df.num_incorrect.gt(0)]\\\n    .head(10)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:52:23.157311Z","iopub.execute_input":"2024-09-23T08:52:23.157720Z","iopub.status.idle":"2024-09-23T08:52:23.182594Z","shell.execute_reply.started":"2024-09-23T08:52:23.157687Z","shell.execute_reply":"2024-09-23T08:52:23.181510Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"    language    label     pred  num_incorrect\n29   English   Contra  Neutral            101\n32   English   Entail  Neutral             98\n30   English   Entail   Contra             82\n28   English   Contra   Entail             69\n33   English  Neutral   Contra             67\n34   English  Neutral   Entail             39\n50    German   Entail  Neutral             14\n100     Thai   Contra   Entail             11\n95   Swahili   Entail  Neutral              9\n122     Urdu   Entail  Neutral              9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>language</th>\n      <th>label</th>\n      <th>pred</th>\n      <th>num_incorrect</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29</th>\n      <td>English</td>\n      <td>Contra</td>\n      <td>Neutral</td>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>English</td>\n      <td>Entail</td>\n      <td>Neutral</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>English</td>\n      <td>Entail</td>\n      <td>Contra</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>English</td>\n      <td>Contra</td>\n      <td>Entail</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>English</td>\n      <td>Neutral</td>\n      <td>Contra</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>English</td>\n      <td>Neutral</td>\n      <td>Entail</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>German</td>\n      <td>Entail</td>\n      <td>Neutral</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>Thai</td>\n      <td>Contra</td>\n      <td>Entail</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Swahili</td>\n      <td>Entail</td>\n      <td>Neutral</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>Urdu</td>\n      <td>Entail</td>\n      <td>Neutral</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"valid\\\n    .assign(\n        _pred = predictions_valid,\n        correct = lambda df: df.label.eq(df._pred),\n        incorrect = lambda df: ~df.correct,\n        pred = lambda df: df._pred.replace(label_map),\n        label = lambda df: df.label.replace(label_map)\n    )\\\n    .loc[lambda df: df.language.eq('English') & ~df.correct & df.label.eq('Contra')]\\\n    [['premise', 'hypothesis', 'label', 'pred']]\\\n    .sample(10, random_state=1)\\\n    .style.hide(axis='index')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T08:55:23.755169Z","iopub.execute_input":"2024-09-23T08:55:23.756243Z","iopub.status.idle":"2024-09-23T08:55:23.774898Z","shell.execute_reply.started":"2024-09-23T08:55:23.756202Z","shell.execute_reply":"2024-09-23T08:55:23.774001Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x78bda405c400>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_4b2b6\">\n  <thead>\n    <tr>\n      <th id=\"T_4b2b6_level0_col0\" class=\"col_heading level0 col0\" >premise</th>\n      <th id=\"T_4b2b6_level0_col1\" class=\"col_heading level0 col1\" >hypothesis</th>\n      <th id=\"T_4b2b6_level0_col2\" class=\"col_heading level0 col2\" >label</th>\n      <th id=\"T_4b2b6_level0_col3\" class=\"col_heading level0 col3\" >pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td id=\"T_4b2b6_row0_col0\" class=\"data row0 col0\" >Using teams can also assist in integrating different perspectives, flattening organizational structure, and streamlining operations.</td>\n      <td id=\"T_4b2b6_row0_col1\" class=\"data row0 col1\" >Organizational structure isn't one of the issues that the team has been known to assist with.</td>\n      <td id=\"T_4b2b6_row0_col2\" class=\"data row0 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row0_col3\" class=\"data row0 col3\" >Neutral</td>\n    </tr>\n    <tr>\n      <td id=\"T_4b2b6_row1_col0\" class=\"data row1 col0\" >Despite their 17th-century origins, these gardens avoid the rigid geometry of the Tuileries and Ver?­sailles.</td>\n      <td id=\"T_4b2b6_row1_col1\" class=\"data row1 col1\" >These gardens were around well before the 17th-century.</td>\n      <td id=\"T_4b2b6_row1_col2\" class=\"data row1 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row1_col3\" class=\"data row1 col3\" >Neutral</td>\n    </tr>\n    <tr>\n      <td id=\"T_4b2b6_row2_col0\" class=\"data row2 col0\" >Jon's defense began to weaken and slow.</td>\n      <td id=\"T_4b2b6_row2_col1\" class=\"data row2 col1\" >Jon felt stronger and more defensive than ever. </td>\n      <td id=\"T_4b2b6_row2_col2\" class=\"data row2 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row2_col3\" class=\"data row2 col3\" >Neutral</td>\n    </tr>\n    <tr>\n      <td id=\"T_4b2b6_row3_col0\" class=\"data row3 col0\" >well this is real interesting that you're as far away as you are because i really thought this was uh uh we're</td>\n      <td id=\"T_4b2b6_row3_col1\" class=\"data row3 col1\" >you're so nearby, it's surprising.</td>\n      <td id=\"T_4b2b6_row3_col2\" class=\"data row3 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row3_col3\" class=\"data row3 col3\" >Entail</td>\n    </tr>\n    <tr>\n      <td id=\"T_4b2b6_row4_col0\" class=\"data row4 col0\" >The Tunnel of Eupalinos can be explored but it's not for the claustrophobic.</td>\n      <td id=\"T_4b2b6_row4_col1\" class=\"data row4 col1\" >The tunnel of Eupalinos is only one foot in diameter, barely large enough for a child to squeeze through.</td>\n      <td id=\"T_4b2b6_row4_col2\" class=\"data row4 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row4_col3\" class=\"data row4 col3\" >Neutral</td>\n    </tr>\n    <tr>\n      <td id=\"T_4b2b6_row5_col0\" class=\"data row5 col0\" >Pro-choicers point out that these close-up images literally cut the fetus's context--the woman--out of the picture.</td>\n      <td id=\"T_4b2b6_row5_col1\" class=\"data row5 col1\" >Pro-choices say the close-up images are fair.</td>\n      <td id=\"T_4b2b6_row5_col2\" class=\"data row5 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row5_col3\" class=\"data row5 col3\" >Neutral</td>\n    </tr>\n    <tr>\n      <td id=\"T_4b2b6_row6_col0\" class=\"data row6 col0\" >Closed on the Sabbath.</td>\n      <td id=\"T_4b2b6_row6_col1\" class=\"data row6 col1\" >Sabbath is closed.</td>\n      <td id=\"T_4b2b6_row6_col2\" class=\"data row6 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row6_col3\" class=\"data row6 col3\" >Entail</td>\n    </tr>\n    <tr>\n      <td id=\"T_4b2b6_row7_col0\" class=\"data row7 col0\" >I see, said Tuppence thoughtfully.</td>\n      <td id=\"T_4b2b6_row7_col1\" class=\"data row7 col1\" >\"I can't comprehend it,\" said Tuppence fitfully.</td>\n      <td id=\"T_4b2b6_row7_col2\" class=\"data row7 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row7_col3\" class=\"data row7 col3\" >Neutral</td>\n    </tr>\n    <tr>\n      <td id=\"T_4b2b6_row8_col0\" class=\"data row8 col0\" >it would probably be a lot more work and probably not turn out as good</td>\n      <td id=\"T_4b2b6_row8_col1\" class=\"data row8 col1\" >Oh that way sounds great, it could turn out even better</td>\n      <td id=\"T_4b2b6_row8_col2\" class=\"data row8 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row8_col3\" class=\"data row8 col3\" >Entail</td>\n    </tr>\n    <tr>\n      <td id=\"T_4b2b6_row9_col0\" class=\"data row9 col0\" >DOD's common practice for managing this environment has been to create aggressive risk reduction efforts in its programs.</td>\n      <td id=\"T_4b2b6_row9_col1\" class=\"data row9 col1\" >The DOD increases risk to manage the environment.</td>\n      <td id=\"T_4b2b6_row9_col2\" class=\"data row9 col2\" >Contra</td>\n      <td id=\"T_4b2b6_row9_col3\" class=\"data row9 col3\" >Neutral</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}